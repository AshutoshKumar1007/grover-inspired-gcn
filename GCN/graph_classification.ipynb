{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c5e6dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c9004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root=\"data/MUTAG\", name=\"MUTAG\")\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:150]\n",
    "test_dataset  = dataset[150:]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce841e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes # 2\n",
    "dataset.num_node_features # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1135a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.W = torch.nn.Parameter(torch.randn(in_dim, out_dim) * 0.01)\n",
    "\n",
    "    def forward(self, A_norm, X):\n",
    "        return A_norm @ X @ self.W\n",
    "    \n",
    "class GraphGCN(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNLayer(in_dim, hidden_dim)\n",
    "        self.gcn2 = GCNLayer(hidden_dim, hidden_dim)\n",
    "        self.classifier = torch.nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, A_norm, X):\n",
    "        H = torch.relu(self.gcn1(A_norm, X))\n",
    "        H = torch.relu(self.gcn2(A_norm, H))\n",
    "\n",
    "        # Graph-level pooling (mean)\n",
    "        g = H.mean(dim=0, keepdim=True)\n",
    "\n",
    "        return self.classifier(g)\n",
    "\n",
    "def normalize_adj(edge_index, num_nodes):\n",
    "    A = to_dense_adj(edge_index, max_num_nodes=num_nodes)[0]\n",
    "\n",
    "    I = torch.eye(num_nodes, device = device)\n",
    "    A_hat = A + I\n",
    "\n",
    "    D = torch.diag(A_hat.sum(dim=1))\n",
    "    D_inv_sqrt = torch.linalg.inv(torch.sqrt(D))\n",
    "\n",
    "    return D_inv_sqrt @ A_hat @ D_inv_sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1e96597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GraphGCN(\n",
    "    in_dim=dataset.num_node_features,\n",
    "    hidden_dim=32,\n",
    "    num_classes=dataset.num_classes\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a33eb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        A_norm = normalize_adj(data.edge_index, data.num_nodes).to(device)\n",
    "        X = data.x\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(A_norm, X)\n",
    "        loss = loss_fn(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            A_norm = normalize_adj(data.edge_index, data.num_nodes).to(device)\n",
    "            X = data.x\n",
    "\n",
    "            out = model(A_norm, X)\n",
    "            pred = out.argmax(dim=1)\n",
    "\n",
    "            correct += (pred == data.y).sum().item()\n",
    "\n",
    "    return correct / len(loader.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb7461b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss 0.6728 | Train Acc 0.693 | Test Acc 0.553\n",
      "Epoch 010 | Loss 0.5822 | Train Acc 0.693 | Test Acc 0.553\n",
      "Epoch 020 | Loss 0.5616 | Train Acc 0.700 | Test Acc 0.553\n",
      "Epoch 030 | Loss 0.5560 | Train Acc 0.713 | Test Acc 0.579\n",
      "Epoch 040 | Loss 0.5459 | Train Acc 0.707 | Test Acc 0.711\n",
      "Epoch 050 | Loss 0.5512 | Train Acc 0.727 | Test Acc 0.763\n",
      "Epoch 060 | Loss 0.5421 | Train Acc 0.740 | Test Acc 0.763\n",
      "Epoch 070 | Loss 0.5389 | Train Acc 0.747 | Test Acc 0.763\n",
      "Epoch 080 | Loss 0.5396 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 090 | Loss 0.5331 | Train Acc 0.740 | Test Acc 0.711\n",
      "Epoch 100 | Loss 0.5340 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 110 | Loss 0.5334 | Train Acc 0.740 | Test Acc 0.737\n",
      "Epoch 120 | Loss 0.5318 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 130 | Loss 0.5307 | Train Acc 0.733 | Test Acc 0.737\n",
      "Epoch 140 | Loss 0.5245 | Train Acc 0.747 | Test Acc 0.763\n",
      "Epoch 150 | Loss 0.5304 | Train Acc 0.727 | Test Acc 0.711\n",
      "Epoch 160 | Loss 0.5293 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 170 | Loss 0.5302 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 180 | Loss 0.5316 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 190 | Loss 0.5317 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 200 | Loss 0.5351 | Train Acc 0.727 | Test Acc 0.711\n",
      "Epoch 210 | Loss 0.5311 | Train Acc 0.727 | Test Acc 0.711\n",
      "Epoch 220 | Loss 0.5302 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 230 | Loss 0.5286 | Train Acc 0.727 | Test Acc 0.711\n",
      "Epoch 240 | Loss 0.5298 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 250 | Loss 0.5307 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 260 | Loss 0.5336 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 270 | Loss 0.5295 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 280 | Loss 0.5294 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 290 | Loss 0.5321 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 300 | Loss 0.5346 | Train Acc 0.733 | Test Acc 0.737\n",
      "Epoch 310 | Loss 0.5290 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 320 | Loss 0.5309 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 330 | Loss 0.5305 | Train Acc 0.727 | Test Acc 0.684\n",
      "Epoch 340 | Loss 0.5288 | Train Acc 0.727 | Test Acc 0.684\n",
      "Epoch 350 | Loss 0.5295 | Train Acc 0.727 | Test Acc 0.684\n",
      "Epoch 360 | Loss 0.5297 | Train Acc 0.733 | Test Acc 0.737\n",
      "Epoch 370 | Loss 0.5292 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 380 | Loss 0.5286 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 390 | Loss 0.5340 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 400 | Loss 0.5302 | Train Acc 0.727 | Test Acc 0.684\n",
      "Epoch 410 | Loss 0.5301 | Train Acc 0.727 | Test Acc 0.711\n",
      "Epoch 420 | Loss 0.5311 | Train Acc 0.727 | Test Acc 0.711\n",
      "Epoch 430 | Loss 0.5283 | Train Acc 0.733 | Test Acc 0.711\n",
      "Epoch 440 | Loss 0.5293 | Train Acc 0.727 | Test Acc 0.763\n",
      "Epoch 450 | Loss 0.5286 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 460 | Loss 0.5309 | Train Acc 0.727 | Test Acc 0.684\n",
      "Epoch 470 | Loss 0.5288 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 480 | Loss 0.5300 | Train Acc 0.727 | Test Acc 0.737\n",
      "Epoch 490 | Loss 0.5302 | Train Acc 0.727 | Test Acc 0.684\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    loss = train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d} | \"\n",
    "            f\"Loss {loss:.4f} | \"\n",
    "            f\"Train Acc {train_acc:.3f} | \"\n",
    "            f\"Test Acc {test_acc:.3f}\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
