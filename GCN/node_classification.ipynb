{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224c1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "A = torch.tensor([\n",
    "    [0, 1, 0, 0],\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 1, 0, 1],\n",
    "    [0, 0, 1, 0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Node features (4 nodes, 3 features each)\n",
    "X = torch.tensor([\n",
    "    [1.0, 0.0, 1.0],\n",
    "    [0.0, 1.0, 1.0],\n",
    "    [1.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "I = torch.eye(A.size(0))\n",
    "A_hat = A + I\n",
    "\n",
    "D_hat = torch.diag(torch.sum(A_hat, dim = 1))\n",
    "D_hat_inv_sqrt = torch.linalg.inv(torch.sqrt(D_hat))\n",
    "\n",
    "A_norm = D_hat_inv_sqrt @ A_hat @ D_hat_inv_sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d94de2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "  def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "    super().__init__()\n",
    "    self.W1 = torch.nn.Parameter(torch.randn(in_dim, hidden_dim))\n",
    "    self.W2 = torch.nn.Parameter(torch.randn(hidden_dim, out_dim))\n",
    "\n",
    "  def forward(self, A_norm , X):\n",
    "    H = torch.relu(A_norm @ X @ self.W1) # 1st Aggreation and projection\n",
    "    H = A_norm @ H @ self.W2 # 2nd Aggregation & projection\n",
    "    return H\n",
    "  \n",
    "\n",
    "class node_classifer(nn.Module):\n",
    "  def __init__(self, in_dim, hidden_dim, num_classes):\n",
    "    super().__init__()\n",
    "    self.l1 = nn.Linear(in_dim, hidden_dim, bias = True)\n",
    "    self.l2 = nn.Linear(hidden_dim, num_classes, bias= True)\n",
    "\n",
    "  def forward(self,H):\n",
    "    out = self.l1(H)\n",
    "    out = torch.relu(out)\n",
    "    logits = self.l2(out)\n",
    "    return logits\n",
    "\n",
    "class classify_model(nn.Module):\n",
    "  def __init__(self, in_dim, hidden_dim, proj_emb, num_classes ):\n",
    "    super().__init__()\n",
    "    self.aggregator = GCN(in_dim, hidden_dim, proj_emb)\n",
    "    self.classifier = node_classifer(proj_emb, hidden_dim, num_classes)\n",
    "\n",
    "  def forward(self, A_norm, X):\n",
    "    H = self.aggregator(A_norm, X)\n",
    "    logits = self.classifier(H)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e59882f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([0, 1, 0, 2])  # size N\n",
    "\n",
    "train_mask = torch.tensor([1, 1, 0, 0], dtype=torch.bool)\n",
    "val_mask   = torch.tensor([0, 0, 1, 1], dtype=torch.bool)\n",
    "#test_mask  = torch.tensor([0, 0, 0, 0, 1, 1], dtype=torch.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58e9a39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss 0.9500 | Train Acc 0.500\n",
      "Epoch 20 | Loss 0.9241 | Train Acc 0.500\n",
      "Epoch 40 | Loss 0.9061 | Train Acc 0.500\n",
      "Epoch 60 | Loss 0.8992 | Train Acc 0.500\n",
      "Epoch 80 | Loss 0.8925 | Train Acc 0.500\n",
      "Epoch 100 | Loss 0.8861 | Train Acc 0.500\n",
      "Epoch 120 | Loss 0.8800 | Train Acc 0.500\n",
      "Epoch 140 | Loss 0.8742 | Train Acc 0.500\n",
      "Epoch 160 | Loss 0.8685 | Train Acc 0.500\n",
      "Epoch 180 | Loss 0.8631 | Train Acc 0.500\n"
     ]
    }
   ],
   "source": [
    "model = classify_model(in_dim = 3, hidden_dim= 4, proj_emb= 4, num_classes= 3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "  model.train()\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  out = model(A_norm, X)        # (N, C)\n",
    "  loss = loss_fn(out[train_mask], labels[train_mask])\n",
    "\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if epoch % 20 == 0:\n",
    "    pred = out.argmax(dim=1)\n",
    "    acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "    print(f\"Epoch {epoch} | Loss {loss:.4f} | Train Acc {acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
